{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parser import DocxParser\n",
    "from chunker import TextChunker\n",
    "from retriever import DenseRetrieverConfig, DenseRetriever\n",
    "from embedding import HuggingFaceEmbedding\n",
    "from llm import QwenChat\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "llm_model = '/home/chenbohua/lz/models/Qwen3-4B'\n",
    "vector_model = '/home/chenbohua/lz/models/bge-base-zh-v1.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a574bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCX_PATH = '/home/chenbohua/lz/初赛A榜/赛题制度文档'\n",
    "dp = DocxParser()\n",
    "tc = TextChunker()\n",
    "all_paragraphs = []\n",
    "all_chunks = []\n",
    "for filepath in tqdm(glob.glob(f'{DOCX_PATH}/*/*.docx')):\n",
    "    paragraphs = dp.parse(filepath)\n",
    "    all_paragraphs.append(paragraphs)\n",
    "for paragraphs in tqdm(all_paragraphs):\n",
    "    chunks = tc.get_chunks(paragraphs, 256)\n",
    "    all_chunks.extend(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ba78bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_config = DenseRetrieverConfig(\n",
    "    model_name_or_path=vector_model,\n",
    "    dim=768,\n",
    "    index_path='./index_store'\n",
    ")\n",
    "embedding_generator = HuggingFaceEmbedding(model_name=vector_model, device='cuda')\n",
    "retriever = DenseRetriever(dense_config, embedding_generator)\n",
    "retriever.build_from_texts(all_chunks)\n",
    "retriever.save_index('./index_store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QwenChat(path=llm_model, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60038270",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMP_DIR = '/home/chenbohua/lz/初赛A榜/数据集A'\n",
    "# 构建用户提问模板\n",
    "def get_query(row):\n",
    "    category = row['category']\n",
    "    question = row['question']\n",
    "    if category == '选择题':\n",
    "        content = row['content']\n",
    "        return f'{category}: {question}\\n{content}'\n",
    "    else:\n",
    "        return f'{category}: {question}'\n",
    "\n",
    "train = pd.read_json(f'{COMP_DIR}/train.json', lines=True)\n",
    "test = pd.read_json(f'{COMP_DIR}/testA.json', lines=True)\n",
    "train['query'] = train.apply(lambda row: get_query(row), axis=1)\n",
    "test['query'] = test.apply(lambda row: get_query(row), axis=1)\n",
    "train_ans = pd.read_json(f'{COMP_DIR}/train_answer.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9992f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for _, row in tqdm(test.iterrows(), total=len(test)):\n",
    "    query = row['query']\n",
    "    contents = retriever.retrieve(query=query, top_k=4)\n",
    "    content = '\\n'.join(['- ' + content['text'] for content in contents])\n",
    "    result, _ = model.chat(query, [], content)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee991520",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['answer'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcefda6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(text):\n",
    "    result = re.sub(r'\\<think\\>[\\s\\S]*\\</think\\>', '', text)\n",
    "    return result.strip()\n",
    "test['answer_p'] = test['answer'].apply(postprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901ed116",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "i0 = 0\n",
    "i1 = 0\n",
    "i2 = 0 \n",
    "for i, row in tqdm(test.iterrows()):\n",
    "    # 正常有答案\n",
    "    if (not re.search(r'\\<think\\>', row['answer_p'])) and (not re.search(r'\\</think\\>', row['answer_p'])):\n",
    "        if row['category'] == '选择题':\n",
    "            res.append(row['answer_p'].split(','))\n",
    "        else:\n",
    "            res.append(row['answer_p'])\n",
    "        i0 += 1\n",
    "    # 只有</think>\n",
    "    elif re.search(r'\\</think\\>', row['answer_p']):\n",
    "        new_ans = row['answer_p'].replace('</think>', '').strip()\n",
    "        if row['category'] == '选择题':\n",
    "            res.append(new_ans.split(','))\n",
    "        else:\n",
    "            res.append(new_ans)\n",
    "        i1 += 1\n",
    "    else:\n",
    "        # 太长了, 没有思考完, 只有 <think>\n",
    "        if row['category'] == '选择题':\n",
    "            res.append(['C']) # 都选 C\n",
    "        else:\n",
    "            res.append(row['answer_p'][-50:]) # 最后五十个字\n",
    "        i2 += 1\n",
    "print(i0, i1, i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e60260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['answer'] = res\n",
    "test[['id', 'answer']].to_json('result.json', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f57396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "data = pd.read_json('result_qw3_14b_bak.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e0ee64fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_count = 0\n",
    "\n",
    "def process(item):\n",
    "    global null_count\n",
    "    if isinstance(item, str):\n",
    "        if '\\n\\n\\n' in item:\n",
    "            item = item.split('\\n\\n\\n')[1].strip()\n",
    "        return item\n",
    "    else:\n",
    "        new_item = []\n",
    "        for i in item:\n",
    "            if '\\n\\n\\n' in i:\n",
    "                i = i.split('\\n\\n\\n')[1].strip()\n",
    "            if i in 'ABCD':\n",
    "                new_item.append(i)\n",
    "        if not len(new_item):\n",
    "            new_item.append('C')\n",
    "            null_count += 1\n",
    "        return new_item\n",
    "\n",
    "data['answer'] = data['answer'].apply(process)\n",
    "null_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4da782c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.to_json('result_qw3_14b.json', lines=True, orient='records', force_ascii=False)\n",
    "data['answer'][6]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
